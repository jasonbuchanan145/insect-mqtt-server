version: '3.8'
services:
  go:
    build: ./go
    volumes:
      - ./shared/temp:/app/temp
    ports:
      - "5688:5688"
    depends_on:
      - activemq
    command: >
      sh -c "
        while ! nc -z activemq 61613; do
          echo 'Waiting for ActiveMQ...'
          sleep 1
        done;
        echo 'ActiveMQ is up!';
        /app/leaf-analyzer-server
      "

  activemq:
    image: apache/activemq-artemis:latest
    ports:
      - "8161:8161" #Web management
      - "61616:61616"
      - "5672:5672"
      - "61613:61613" #The stomp port, the rest of the ports aren't used but for completeness might as well leave them open
      - "1883:1883" #This is interesting, it's the mqtt port, not currently used but maybe in future
      - "61614:61614"

  python-cuda:
    build:
      context: ./pytorch_model
      dockerfile: Dockerfile
    volumes:
      - ./shared/temp:/app/temp
      #Add a second directory because after processing the python script writes to disk
      - ./shared/processed:/app/processed
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      #Conda buffers all the output, don't do that https://github.com/conda/conda/issues/9412
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
    depends_on:
      - activemq
    command: >
      sh -c "
        while ! nc -z activemq 61613; do
          echo 'Waiting for ActiveMQ...'
          sleep 1
        done;
        echo 'ActiveMQ is up!';
        . /opt/conda/etc/profile.d/conda.sh
        conda activate env 
        python queue_runner.py
      "
volumes:
  shared:
